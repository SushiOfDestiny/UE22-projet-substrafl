{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ds, test_ds), metadata = tfds.load('colorectal_histology',split=['train[:80%]','train[80%:]'],with_info=True,\n",
    "        as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Sequential):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__(layers=[\n",
    "            tf.keras.layers.Rescaling(1./255, input_shape=(150,150,3)), # input length = 150\n",
    "            tf.keras.layers.Conv2D(32, 5, activation='relu'), # output length = input length - 4 = 146\n",
    "            tf.keras.layers.MaxPooling2D(), # pool_size = (2,2) -> output length = input length / 2 = 73\n",
    "            tf.keras.layers.Conv2D(32, 5, activation='relu'), # output length = 69\n",
    "            tf.keras.layers.MaxPooling2D(), # output length = 34\n",
    "            tf.keras.layers.Conv2D(32, 5, activation='relu'), # output length = 30\n",
    "            tf.keras.layers.MaxPooling2D(), # output length = 15\n",
    "            tf.keras.layers.Flatten(), # output length = 32 * 15 * 3 = 1440\n",
    "            tf.keras.layers.Dense(7200, activation='relu'),\n",
    "            tf.keras.layers.Dense(8)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=criterion, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_6 (Rescaling)     (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 146, 146, 32)      2432      \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 73, 73, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 69, 69, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 34, 34, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 30, 30, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 7200)              51847200  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8)                 57608     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,958,504\n",
      "Trainable params: 51,958,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7200"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15*15*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jules\\fichiers_git\\UE22-projet-substrafl\\histo_class\\test_model.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jules/fichiers_git/UE22-projet-substrafl/histo_class/test_model.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jules/fichiers_git/UE22-projet-substrafl/histo_class/test_model.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   train_ds\u001b[39m.\u001b[39;49mbatch(\u001b[39m1\u001b[39;49m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jules/fichiers_git/UE22-projet-substrafl/histo_class/test_model.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jules/fichiers_git/UE22-projet-substrafl/histo_class/test_model.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jules/fichiers_git/UE22-projet-substrafl/histo_class/test_model.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\miniconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\miniconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:935\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    933\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    934\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m--> 935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    937\u001b[0m   \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m    939\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds.batch(1),\n",
    "  batch_size=1,\n",
    "  epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
